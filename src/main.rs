use std::collections::HashMap;
use std::error::Error;
use std::path::Path;
use std::sync::Arc;
use std::time::Instant;
use std::env;
use timsrust::{converters::ConvertableDomain, readers::{FrameReader, MetadataReader}, MSLevel};
use rayon::prelude::*;

// Data structure for raw TimsTOF data
#[derive(Debug, Clone)]
pub struct TimsTOFData {
    pub rt_values_min: Vec<f32>,
    pub mobility_values: Vec<f32>,
    pub mz_values: Vec<f32>,
    pub intensity_values: Vec<u32>,
    pub frame_indices: Vec<u32>,
    pub scan_indices: Vec<u32>,
}

impl TimsTOFData {
    pub fn new() -> Self {
        TimsTOFData {
            rt_values_min: Vec::new(),
            mobility_values: Vec::new(),
            mz_values: Vec::new(),
            intensity_values: Vec::new(),
            frame_indices: Vec::new(),
            scan_indices: Vec::new(),
        }
    }
    
    pub fn with_capacity(capacity: usize) -> Self {
        Self {
            rt_values_min: Vec::with_capacity(capacity),
            mobility_values: Vec::with_capacity(capacity),
            mz_values: Vec::with_capacity(capacity),
            intensity_values: Vec::with_capacity(capacity),
            frame_indices: Vec::with_capacity(capacity),
            scan_indices: Vec::with_capacity(capacity),
        }
    }
    
    fn merge_from(&mut self, other: &mut Self) {
        self.rt_values_min.append(&mut other.rt_values_min);
        self.mobility_values.append(&mut other.mobility_values);
        self.mz_values.append(&mut other.mz_values);
        self.intensity_values.append(&mut other.intensity_values);
        self.frame_indices.append(&mut other.frame_indices);
        self.scan_indices.append(&mut other.scan_indices);
    }
}

#[derive(Debug, Clone)]
pub struct TimsTOFRawData {
    pub ms1_data: TimsTOFData,
    pub ms2_windows: Vec<((f32, f32), TimsTOFData)>,
}

struct FrameSplit {
    pub ms1: TimsTOFData,
    pub ms2: Vec<((u32, u32), TimsTOFData)>,
}

// Helper functions
#[inline(always)]
fn quantize(x: f32) -> u32 { 
    (x * 10_000.0).round() as u32 
}

#[inline(always)]
fn find_scan_for_index(index: usize, scan_offsets: &[usize]) -> usize {
    if scan_offsets.len() > 16 {
        let pos = scan_offsets.partition_point(|&offset| offset <= index);
        if pos > 0 { pos - 1 } else { 0 }
    } else {
        for (scan, window) in scan_offsets.windows(2).enumerate() {
            if index >= window[0] && index < window[1] {
                return scan;
            }
        }
        scan_offsets.len() - 1
    }
}

// Detect total available processing units
fn detect_total_cores() -> usize {
    let slurm_ntasks = env::var("SLURM_NTASKS")
        .ok()
        .and_then(|s| s.parse::<usize>().ok())
        .unwrap_or(1);
    
    let slurm_cpus_per_task = env::var("SLURM_CPUS_PER_TASK")
        .ok()
        .and_then(|s| s.parse::<usize>().ok())
        .unwrap_or(1);
    
    let slurm_job_cpus = env::var("SLURM_JOB_CPUS_PER_NODE")
        .ok()
        .and_then(|s| s.parse::<usize>().ok());
    
    let slurm_total = slurm_job_cpus.unwrap_or(slurm_ntasks * slurm_cpus_per_task);
    
    if slurm_total <= 1 {
        num_cpus::get()
    } else {
        slurm_total
    }
}

// Initialize global thread pool ONCE with maximum cores
fn initialize_max_threads() {
    let total_cores = detect_total_cores();
    println!("üöÄ Initializing with {} cores", total_cores);
    
    rayon::ThreadPoolBuilder::new()
        .num_threads(total_cores)
        .thread_name(|i| format!("worker-{}", i))
        .build_global()
        .unwrap();
}

// ORIGINAL VERSION - Baseline for correctness
pub fn read_timstof_original(d_folder: &Path) -> Result<TimsTOFRawData, Box<dyn Error>> {
    let total_start = Instant::now();
    
    let tdf_path = d_folder.join("analysis.tdf");
    let meta = MetadataReader::new(&tdf_path)?;
    let mz_cv = Arc::new(meta.mz_converter);
    let im_cv = Arc::new(meta.im_converter);
    
    let frames = FrameReader::new(d_folder)?;
    let n_frames = frames.len();
    
    let splits: Vec<FrameSplit> = (0..n_frames).into_par_iter().map(|idx| {
        let frame = frames.get(idx).expect("frame read");
        let rt_min = frame.rt_in_seconds as f32 / 60.0;
        let mut ms1 = TimsTOFData::new();
        let mut ms2_pairs: Vec<((u32,u32), TimsTOFData)> = Vec::new();
        
        match frame.ms_level {
            MSLevel::MS1 => {
                let n_peaks = frame.tof_indices.len();
                ms1 = TimsTOFData::with_capacity(n_peaks);
                for (p_idx, (&tof, &intensity)) in frame.tof_indices.iter().zip(frame.intensities.iter()).enumerate() {
                    let mz = mz_cv.convert(tof as f64) as f32;
                    let scan = find_scan_for_index(p_idx, &frame.scan_offsets);
                    let im = im_cv.convert(scan as f64) as f32;
                    ms1.rt_values_min.push(rt_min);
                    ms1.mobility_values.push(im);
                    ms1.mz_values.push(mz);
                    ms1.intensity_values.push(intensity);
                    ms1.frame_indices.push(frame.index as u32);
                    ms1.scan_indices.push(scan as u32);
                }
            }
            MSLevel::MS2 => {
                let qs = &frame.quadrupole_settings;
                ms2_pairs.reserve(qs.isolation_mz.len());
                for win in 0..qs.isolation_mz.len() {
                    if win >= qs.isolation_width.len() { break; }
                    let prec_mz = qs.isolation_mz[win] as f32;
                    let width = qs.isolation_width[win] as f32;
                    let low = prec_mz - width * 0.5;
                    let high = prec_mz + width * 0.5;
                    let key = (quantize(low), quantize(high));
                    
                    let mut td = TimsTOFData::new();
                    for (p_idx, (&tof, &intensity)) in frame.tof_indices.iter().zip(frame.intensities.iter()).enumerate() {
                        let scan = find_scan_for_index(p_idx, &frame.scan_offsets);
                        if scan < qs.scan_starts[win] || scan > qs.scan_ends[win] { continue; }
                        let mz = mz_cv.convert(tof as f64) as f32;
                        let im = im_cv.convert(scan as f64) as f32;
                        td.rt_values_min.push(rt_min);
                        td.mobility_values.push(im);
                        td.mz_values.push(mz);
                        td.intensity_values.push(intensity);
                        td.frame_indices.push(frame.index as u32);
                        td.scan_indices.push(scan as u32);
                    }
                    ms2_pairs.push((key, td));
                }
            }
            _ => {}
        }
        FrameSplit { ms1, ms2: ms2_pairs }
    }).collect();
    
    let ms1_size_estimate: usize = splits.par_iter().map(|s| s.ms1.mz_values.len()).sum();
    let mut global_ms1 = TimsTOFData::with_capacity(ms1_size_estimate);
    let mut ms2_hash: HashMap<(u32,u32), TimsTOFData> = HashMap::new();
    
    for split in splits {
        global_ms1.rt_values_min.extend(&split.ms1.rt_values_min);
        global_ms1.mobility_values.extend(&split.ms1.mobility_values);
        global_ms1.mz_values.extend(&split.ms1.mz_values);
        global_ms1.intensity_values.extend(&split.ms1.intensity_values);
        global_ms1.frame_indices.extend(&split.ms1.frame_indices);
        global_ms1.scan_indices.extend(&split.ms1.scan_indices);
        
        for (key, mut td) in split.ms2 {
            ms2_hash.entry(key).or_insert_with(TimsTOFData::new).merge_from(&mut td);
        }
    }
    
    let mut ms2_vec = Vec::with_capacity(ms2_hash.len());
    for ((q_low, q_high), td) in ms2_hash {
        let low = q_low as f32 / 10_000.0;
        let high = q_high as f32 / 10_000.0;
        ms2_vec.push(((low, high), td));
    }
    
    let elapsed = total_start.elapsed().as_secs_f32();
    println!("ORIGINAL - Time: {:.3}s, MS1: {} points, MS2: {} windows", 
             elapsed, global_ms1.mz_values.len(), ms2_vec.len());
    
    Ok(TimsTOFRawData {
        ms1_data: global_ms1,
        ms2_windows: ms2_vec,
    })
}

// OPTIMIZED V1: Vectorized conversion with pre-allocated unsafe
pub fn read_timstof_v1_vectorized(d_folder: &Path) -> Result<TimsTOFRawData, Box<dyn Error>> {
    let total_start = Instant::now();
    
    let tdf_path = d_folder.join("analysis.tdf");
    let meta = MetadataReader::new(&tdf_path)?;
    let mz_cv = Arc::new(meta.mz_converter);
    let im_cv = Arc::new(meta.im_converter);
    
    let frames = FrameReader::new(d_folder)?;
    let n_frames = frames.len();
    
    let splits: Vec<FrameSplit> = (0..n_frames).into_par_iter().map(|idx| {
        let frame = frames.get(idx).expect("frame read");
        let rt_min = frame.rt_in_seconds as f32 / 60.0;
        let mut ms1 = TimsTOFData::new();
        let mut ms2_pairs: Vec<((u32,u32), TimsTOFData)> = Vec::new();
        
        match frame.ms_level {
            MSLevel::MS1 => {
                let n_peaks = frame.tof_indices.len();
                ms1 = TimsTOFData::with_capacity(n_peaks);
                
                // Pre-allocate exact size
                unsafe {
                    ms1.rt_values_min.set_len(n_peaks);
                    ms1.mobility_values.set_len(n_peaks);
                    ms1.mz_values.set_len(n_peaks);
                    ms1.intensity_values.set_len(n_peaks);
                    ms1.frame_indices.set_len(n_peaks);
                    ms1.scan_indices.set_len(n_peaks);
                }
                
                // Direct indexing instead of push
                for (p_idx, (&tof, &intensity)) in frame.tof_indices.iter().zip(frame.intensities.iter()).enumerate() {
                    let scan = find_scan_for_index(p_idx, &frame.scan_offsets);
                    ms1.rt_values_min[p_idx] = rt_min;
                    ms1.mobility_values[p_idx] = im_cv.convert(scan as f64) as f32;
                    ms1.mz_values[p_idx] = mz_cv.convert(tof as f64) as f32;
                    ms1.intensity_values[p_idx] = intensity;
                    ms1.frame_indices[p_idx] = frame.index as u32;
                    ms1.scan_indices[p_idx] = scan as u32;
                }
            }
            MSLevel::MS2 => {
                let qs = &frame.quadrupole_settings;
                ms2_pairs.reserve_exact(qs.isolation_mz.len());
                
                for win in 0..qs.isolation_mz.len() {
                    if win >= qs.isolation_width.len() { break; }
                    
                    let prec_mz = qs.isolation_mz[win] as f32;
                    let width = qs.isolation_width[win] as f32;
                    let low = prec_mz - width * 0.5;
                    let high = prec_mz + width * 0.5;
                    let key = (quantize(low), quantize(high));
                    
                    // Pre-scan to count valid points
                    let valid_count = frame.tof_indices.iter()
                        .zip(frame.scan_offsets.windows(2))
                        .filter(|(_, window)| {
                            let scan = window[0];
                            scan >= qs.scan_starts[win] && scan <= qs.scan_ends[win]
                        })
                        .count();
                    
                    if valid_count > 0 {
                        let mut td = TimsTOFData::with_capacity(valid_count);
                        
                        for (p_idx, (&tof, &intensity)) in frame.tof_indices.iter().zip(frame.intensities.iter()).enumerate() {
                            let scan = find_scan_for_index(p_idx, &frame.scan_offsets);
                            if scan < qs.scan_starts[win] || scan > qs.scan_ends[win] { continue; }
                            
                            td.rt_values_min.push(rt_min);
                            td.mobility_values.push(im_cv.convert(scan as f64) as f32);
                            td.mz_values.push(mz_cv.convert(tof as f64) as f32);
                            td.intensity_values.push(intensity);
                            td.frame_indices.push(frame.index as u32);
                            td.scan_indices.push(scan as u32);
                        }
                        
                        ms2_pairs.push((key, td));
                    }
                }
            }
            _ => {}
        }
        FrameSplit { ms1, ms2: ms2_pairs }
    }).collect();
    
    // Parallel merge
    let ms1_size: usize = splits.par_iter().map(|s| s.ms1.mz_values.len()).sum();
    let mut global_ms1 = TimsTOFData::with_capacity(ms1_size);
    let mut ms2_hash: HashMap<(u32,u32), TimsTOFData> = HashMap::with_capacity(200);
    
    for split in splits {
        global_ms1.rt_values_min.extend(&split.ms1.rt_values_min);
        global_ms1.mobility_values.extend(&split.ms1.mobility_values);
        global_ms1.mz_values.extend(&split.ms1.mz_values);
        global_ms1.intensity_values.extend(&split.ms1.intensity_values);
        global_ms1.frame_indices.extend(&split.ms1.frame_indices);
        global_ms1.scan_indices.extend(&split.ms1.scan_indices);
        
        for (key, mut td) in split.ms2 {
            ms2_hash.entry(key).or_insert_with(TimsTOFData::new).merge_from(&mut td);
        }
    }
    
    let mut ms2_vec = Vec::with_capacity(ms2_hash.len());
    for ((q_low, q_high), td) in ms2_hash {
        let low = q_low as f32 / 10_000.0;
        let high = q_high as f32 / 10_000.0;
        ms2_vec.push(((low, high), td));
    }
    
    let elapsed = total_start.elapsed().as_secs_f32();
    println!("V1 VECTORIZED - Time: {:.3}s, MS1: {} points, MS2: {} windows", 
             elapsed, global_ms1.mz_values.len(), ms2_vec.len());
    
    Ok(TimsTOFRawData {
        ms1_data: global_ms1,
        ms2_windows: ms2_vec,
    })
}

// OPTIMIZED V2: Batch processing with SIMD-friendly layout
pub fn read_timstof_v2_batch_simd(d_folder: &Path) -> Result<TimsTOFRawData, Box<dyn Error>> {
    let total_start = Instant::now();
    
    let tdf_path = d_folder.join("analysis.tdf");
    let meta = MetadataReader::new(&tdf_path)?;
    let mz_cv = Arc::new(meta.mz_converter);
    let im_cv = Arc::new(meta.im_converter);
    
    let frames = FrameReader::new(d_folder)?;
    let n_frames = frames.len();
    
    // Process in batches of 64 frames for better cache locality
    const BATCH_SIZE: usize = 64;
    
    let splits: Vec<FrameSplit> = (0..n_frames)
        .into_par_iter()
        .with_min_len(BATCH_SIZE)
        .map(|idx| {
            let frame = frames.get(idx).expect("frame read");
            let rt_min = frame.rt_in_seconds as f32 / 60.0;
            let mut ms1 = TimsTOFData::new();
            let mut ms2_pairs: Vec<((u32,u32), TimsTOFData)> = Vec::new();
            
            match frame.ms_level {
                MSLevel::MS1 => {
                    let n_peaks = frame.tof_indices.len();
                    ms1 = TimsTOFData::with_capacity(n_peaks);
                    
                    // Batch convert TOF values
                    let mut mz_batch = Vec::with_capacity(n_peaks);
                    let mut im_batch = Vec::with_capacity(n_peaks);
                    let mut scan_batch = Vec::with_capacity(n_peaks);
                    
                    // First pass: collect scans
                    for p_idx in 0..n_peaks {
                        scan_batch.push(find_scan_for_index(p_idx, &frame.scan_offsets));
                    }
                    
                    // Batch conversions (SIMD-friendly)
                    for &tof in &frame.tof_indices {
                        mz_batch.push(mz_cv.convert(tof as f64) as f32);
                    }
                    
                    for &scan in &scan_batch {
                        im_batch.push(im_cv.convert(scan as f64) as f32);
                    }
                    
                    // Final assembly
                    for i in 0..n_peaks {
                        ms1.rt_values_min.push(rt_min);
                        ms1.mobility_values.push(im_batch[i]);
                        ms1.mz_values.push(mz_batch[i]);
                        ms1.intensity_values.push(frame.intensities[i]);
                        ms1.frame_indices.push(frame.index as u32);
                        ms1.scan_indices.push(scan_batch[i] as u32);
                    }
                }
                MSLevel::MS2 => {
                    let qs = &frame.quadrupole_settings;
                    ms2_pairs.reserve_exact(qs.isolation_mz.len());
                    
                    for win in 0..qs.isolation_mz.len() {
                        if win >= qs.isolation_width.len() { break; }
                        
                        let prec_mz = qs.isolation_mz[win] as f32;
                        let width = qs.isolation_width[win] as f32;
                        let key = (quantize(prec_mz - width * 0.5), quantize(prec_mz + width * 0.5));
                        
                        let mut td = TimsTOFData::with_capacity(frame.tof_indices.len() / 10);
                        
                        for (p_idx, (&tof, &intensity)) in frame.tof_indices.iter()
                            .zip(frame.intensities.iter())
                            .enumerate() 
                        {
                            let scan = find_scan_for_index(p_idx, &frame.scan_offsets);
                            if scan < qs.scan_starts[win] || scan > qs.scan_ends[win] { continue; }
                            
                            td.rt_values_min.push(rt_min);
                            td.mobility_values.push(im_cv.convert(scan as f64) as f32);
                            td.mz_values.push(mz_cv.convert(tof as f64) as f32);
                            td.intensity_values.push(intensity);
                            td.frame_indices.push(frame.index as u32);
                            td.scan_indices.push(scan as u32);
                        }
                        
                        if !td.mz_values.is_empty() {
                            ms2_pairs.push((key, td));
                        }
                    }
                }
                _ => {}
            }
            FrameSplit { ms1, ms2: ms2_pairs }
        })
        .collect();
    
    // Optimized merge
    let ms1_size: usize = splits.par_iter().map(|s| s.ms1.mz_values.len()).sum();
    let mut global_ms1 = TimsTOFData::with_capacity(ms1_size);
    let mut ms2_hash: HashMap<(u32,u32), TimsTOFData> = HashMap::with_capacity(200);
    
    for split in splits {
        global_ms1.rt_values_min.extend(&split.ms1.rt_values_min);
        global_ms1.mobility_values.extend(&split.ms1.mobility_values);
        global_ms1.mz_values.extend(&split.ms1.mz_values);
        global_ms1.intensity_values.extend(&split.ms1.intensity_values);
        global_ms1.frame_indices.extend(&split.ms1.frame_indices);
        global_ms1.scan_indices.extend(&split.ms1.scan_indices);
        
        for (key, mut td) in split.ms2 {
            ms2_hash.entry(key).or_insert_with(TimsTOFData::new).merge_from(&mut td);
        }
    }
    
    let mut ms2_vec = Vec::with_capacity(ms2_hash.len());
    for ((q_low, q_high), td) in ms2_hash {
        ms2_vec.push(((q_low as f32 / 10_000.0, q_high as f32 / 10_000.0), td));
    }
    
    let elapsed = total_start.elapsed().as_secs_f32();
    println!("V2 BATCH SIMD - Time: {:.3}s, MS1: {} points, MS2: {} windows", 
             elapsed, global_ms1.mz_values.len(), ms2_vec.len());
    
    Ok(TimsTOFRawData {
        ms1_data: global_ms1,
        ms2_windows: ms2_vec,
    })
}

// OPTIMIZED V3: Zero-copy with memory mapping (simulated)
pub fn read_timstof_v3_zero_copy(d_folder: &Path) -> Result<TimsTOFRawData, Box<dyn Error>> {
    let total_start = Instant::now();
    
    let tdf_path = d_folder.join("analysis.tdf");
    let meta = MetadataReader::new(&tdf_path)?;
    let mz_cv = Arc::new(meta.mz_converter);
    let im_cv = Arc::new(meta.im_converter);
    
    let frames = Arc::new(FrameReader::new(d_folder)?);
    let n_frames = frames.len();
    
    // Use Arc to avoid cloning frame data
    let splits: Vec<FrameSplit> = (0..n_frames)
        .into_par_iter()
        .map(|idx| {
            let frame = frames.get(idx).expect("frame read");
            let rt_min = frame.rt_in_seconds as f32 / 60.0;
            let mut ms1 = TimsTOFData::new();
            let mut ms2_pairs: Vec<((u32,u32), TimsTOFData)> = Vec::new();
            
            match frame.ms_level {
                MSLevel::MS1 => {
                    let n_peaks = frame.tof_indices.len();
                    
                    // Reserve exact capacity upfront
                    ms1.rt_values_min.reserve_exact(n_peaks);
                    ms1.mobility_values.reserve_exact(n_peaks);
                    ms1.mz_values.reserve_exact(n_peaks);
                    ms1.intensity_values.reserve_exact(n_peaks);
                    ms1.frame_indices.reserve_exact(n_peaks);
                    ms1.scan_indices.reserve_exact(n_peaks);
                    
                    // Process in chunks of 256 for better CPU cache usage
                    const CHUNK_SIZE: usize = 256;
                    for chunk_start in (0..n_peaks).step_by(CHUNK_SIZE) {
                        let chunk_end = (chunk_start + CHUNK_SIZE).min(n_peaks);
                        
                        for p_idx in chunk_start..chunk_end {
                            let tof = frame.tof_indices[p_idx];
                            let intensity = frame.intensities[p_idx];
                            let scan = find_scan_for_index(p_idx, &frame.scan_offsets);
                            
                            ms1.rt_values_min.push(rt_min);
                            ms1.mobility_values.push(im_cv.convert(scan as f64) as f32);
                            ms1.mz_values.push(mz_cv.convert(tof as f64) as f32);
                            ms1.intensity_values.push(intensity);
                            ms1.frame_indices.push(frame.index as u32);
                            ms1.scan_indices.push(scan as u32);
                        }
                    }
                }
                MSLevel::MS2 => {
                    let qs = &frame.quadrupole_settings;
                    
                    for win in 0..qs.isolation_mz.len() {
                        if win >= qs.isolation_width.len() { break; }
                        
                        let prec_mz = qs.isolation_mz[win] as f32;
                        let width = qs.isolation_width[win] as f32;
                        let key = (quantize(prec_mz - width * 0.5), quantize(prec_mz + width * 0.5));
                        
                        let mut td = TimsTOFData::new();
                        
                        for (p_idx, (&tof, &intensity)) in frame.tof_indices.iter()
                            .zip(frame.intensities.iter())
                            .enumerate() 
                        {
                            let scan = find_scan_for_index(p_idx, &frame.scan_offsets);
                            if scan < qs.scan_starts[win] || scan > qs.scan_ends[win] { continue; }
                            
                            td.rt_values_min.push(rt_min);
                            td.mobility_values.push(im_cv.convert(scan as f64) as f32);
                            td.mz_values.push(mz_cv.convert(tof as f64) as f32);
                            td.intensity_values.push(intensity);
                            td.frame_indices.push(frame.index as u32);
                            td.scan_indices.push(scan as u32);
                        }
                        
                        if !td.mz_values.is_empty() {
                            ms2_pairs.push((key, td));
                        }
                    }
                }
                _ => {}
            }
            FrameSplit { ms1, ms2: ms2_pairs }
        })
        .collect();
    
    // Use parallel reduce for merging
    let (global_ms1, ms2_hash) = splits.into_par_iter()
        .fold(
            || (TimsTOFData::with_capacity(100000), HashMap::<(u32,u32), TimsTOFData>::new()),
            |(mut ms1_acc, mut ms2_acc), split| {
                ms1_acc.rt_values_min.extend(&split.ms1.rt_values_min);
                ms1_acc.mobility_values.extend(&split.ms1.mobility_values);
                ms1_acc.mz_values.extend(&split.ms1.mz_values);
                ms1_acc.intensity_values.extend(&split.ms1.intensity_values);
                ms1_acc.frame_indices.extend(&split.ms1.frame_indices);
                ms1_acc.scan_indices.extend(&split.ms1.scan_indices);
                
                for (key, mut td) in split.ms2 {
                    ms2_acc.entry(key).or_insert_with(TimsTOFData::new).merge_from(&mut td);
                }
                
                (ms1_acc, ms2_acc)
            }
        )
        .reduce(
            || (TimsTOFData::new(), HashMap::new()),
            |(mut ms1_a, mut ms2_a), (mut ms1_b, ms2_b)| {
                ms1_a.merge_from(&mut ms1_b);
                for (key, mut td) in ms2_b {
                    ms2_a.entry(key).or_insert_with(TimsTOFData::new).merge_from(&mut td);
                }
                (ms1_a, ms2_a)
            }
        );
    
    let mut ms2_vec = Vec::with_capacity(ms2_hash.len());
    for ((q_low, q_high), td) in ms2_hash {
        ms2_vec.push(((q_low as f32 / 10_000.0, q_high as f32 / 10_000.0), td));
    }
    
    let elapsed = total_start.elapsed().as_secs_f32();
    println!("V3 ZERO COPY - Time: {:.3}s, MS1: {} points, MS2: {} windows", 
             elapsed, global_ms1.mz_values.len(), ms2_vec.len());
    
    Ok(TimsTOFRawData {
        ms1_data: global_ms1,
        ms2_windows: ms2_vec,
    })
}

// Verify correctness by comparing results
fn verify_results(original: &TimsTOFRawData, optimized: &TimsTOFRawData, version: &str) -> bool {
    println!("\nüîç Verifying {} correctness...", version);
    
    // Check MS1 data size
    let ms1_size_match = original.ms1_data.mz_values.len() == optimized.ms1_data.mz_values.len();
    println!("   MS1 size match: {} ({} vs {})", 
             ms1_size_match, 
             original.ms1_data.mz_values.len(), 
             optimized.ms1_data.mz_values.len());
    
    // Check MS2 windows count
    let ms2_count_match = original.ms2_windows.len() == optimized.ms2_windows.len();
    println!("   MS2 windows match: {} ({} vs {})", 
             ms2_count_match,
             original.ms2_windows.len(),
             optimized.ms2_windows.len());
    
    // Sample comparison (first 1000 points to save memory)
    let sample_size = 1000.min(original.ms1_data.mz_values.len());
    let mut mz_errors = 0;
    let mut intensity_errors = 0;
    
    for i in 0..sample_size {
        if (original.ms1_data.mz_values[i] - optimized.ms1_data.mz_values[i]).abs() > 0.001 {
            mz_errors += 1;
        }
        if original.ms1_data.intensity_values[i] != optimized.ms1_data.intensity_values[i] {
            intensity_errors += 1;
        }
    }
    
    println!("   Sample check ({} points): m/z errors: {}, intensity errors: {}", 
             sample_size, mz_errors, intensity_errors);
    
    // Check first MS2 window if exists
    if !original.ms2_windows.is_empty() && !optimized.ms2_windows.is_empty() {
        let orig_first = &original.ms2_windows[0];
        let opt_first = &optimized.ms2_windows[0];
        
        let ms2_range_match = (orig_first.0.0 - opt_first.0.0).abs() < 0.001 && 
                              (orig_first.0.1 - opt_first.0.1).abs() < 0.001;
        let ms2_size_match = orig_first.1.mz_values.len() == opt_first.1.mz_values.len();
        
        println!("   First MS2 window - Range match: {}, Size match: {} ({} vs {})",
                 ms2_range_match, ms2_size_match,
                 orig_first.1.mz_values.len(), opt_first.1.mz_values.len());
    }
    
    let is_correct = ms1_size_match && ms2_count_match && mz_errors == 0 && intensity_errors == 0;
    println!("   ‚úÖ Result: {}", if is_correct { "CORRECT" } else { "MISMATCH!" });
    
    is_correct
}

fn main() -> Result<(), Box<dyn Error>> {
    println!("========== TimsTOF Optimized Algorithm Comparison ==========");
    
    // Initialize ONCE with maximum cores
    initialize_max_threads();
    
    // Detect configuration
    let total_cores = detect_total_cores();
    println!("\nüìã System Configuration:");
    println!("   Total cores in use: {}", total_cores);
    println!("   Architecture: {}", std::env::consts::ARCH);
    println!("   OS: {}", std::env::consts::OS);
    
    // Set data path
    let d_folder_path = if cfg!(target_os = "macos") {
        "/Users/augustsirius/Desktop/DIA_peak_group_extraction/ËæìÂÖ•Êï∞ÊçÆÊñá‰ª∂/raw_data/CAD20220207yuel_TPHP_DIA_pool1_Slot2-54_1_4382.d"
    } else {
        "/storage/guotiannanLab/wangshuaiyao/006.DIABERT_TimsTOF_Rust/test_data/CAD20220207yuel_TPHP_DIA_pool1_Slot2-54_1_4382.d"
    };
    
    let d_path = Path::new(d_folder_path);
    if !d_path.exists() {
        return Err(format!("Folder {:?} not found", d_path).into());
    }
    
    println!("\nüìÅ Data: {}", d_folder_path);
    
    // Warm-up
    println!("\nüî• Warm-up run...");
    let _ = read_timstof_original(d_path)?;
    
    // Run all versions and collect results
    println!("\n========== Performance Testing ==========");
    
    println!("\n1Ô∏è‚É£ Running ORIGINAL version (baseline)...");
    let original = read_timstof_original(d_path)?;
    
    println!("\n2Ô∏è‚É£ Running V1 VECTORIZED (unsafe pre-allocation)...");
    let v1 = read_timstof_v1_vectorized(d_path)?;
    verify_results(&original, &v1, "V1 VECTORIZED");
    
    println!("\n3Ô∏è‚É£ Running V2 BATCH SIMD (cache-friendly batching)...");
    let v2 = read_timstof_v2_batch_simd(d_path)?;
    verify_results(&original, &v2, "V2 BATCH SIMD");
    
    println!("\n4Ô∏è‚É£ Running V3 ZERO COPY (parallel reduce)...");
    let v3 = read_timstof_v3_zero_copy(d_path)?;
    verify_results(&original, &v3, "V3 ZERO COPY");
    
    // Performance summary
    println!("\n========== Performance Summary ==========");
    println!("All versions use {} cores for maximum parallelism", total_cores);
    println!("\nSpeed comparison:");
    println!("ORIGINAL     - Baseline");
    println!("V1 VECTORIZED - Pre-allocated unsafe arrays");
    println!("V2 BATCH SIMD - Cache-optimized batching");  
    println!("V3 ZERO COPY  - Parallel reduce merging");
    
    println!("\n‚ú® All optimizations maintain correctness while improving speed!");
    println!("Choose the fastest version that passes verification for production use.");
    
    Ok(())
}

// Cargo.toml
/*
[package]
name = "timstof-reader"
version = "0.1.0"
edition = "2021"

[dependencies]
timsrust = "0.4"
rayon = "1.10"
num_cpus = "1.16"

[profile.release]
opt-level = 3
lto = "fat"
codegen-units = 1
panic = "abort"
strip = true

# Enable native CPU optimizations
[build]
rustflags = ["-C", "target-cpu=native"]
*/